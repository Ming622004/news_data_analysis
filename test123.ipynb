{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15992\n",
      "已處理資料: 500\n",
      "已處理資料: 1000\n",
      "已處理資料: 1500\n",
      "已處理資料: 2000\n",
      "已處理資料: 2500\n",
      "已處理資料: 3000\n",
      "已處理資料: 3500\n",
      "已處理資料: 4000\n",
      "已處理資料: 4500\n",
      "已處理資料: 5000\n",
      "已處理資料: 5500\n",
      "已處理資料: 6000\n",
      "已處理資料: 6500\n",
      "已處理資料: 7000\n",
      "已處理資料: 7500\n",
      "已處理資料: 8000\n",
      "已處理資料: 8500\n",
      "已處理資料: 9000\n",
      "已處理資料: 9500\n",
      "已處理資料: 10000\n",
      "已處理資料: 10500\n",
      "已處理資料: 11000\n",
      "已處理資料: 11500\n",
      "已處理資料: 12000\n",
      "已處理資料: 12500\n",
      "已處理資料: 13000\n",
      "已處理資料: 13500\n",
      "已處理資料: 14000\n",
      "已處理資料: 14500\n",
      "已處理資料: 15000\n",
      "已處理資料: 15500\n"
     ]
    }
   ],
   "source": [
    "import MySQLdb\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import sys\n",
    "import cb104_addr\n",
    "\n",
    "# \"CT\" \"apple\" \"storm\" \"udn\"\n",
    "paper_name = \"apple\"\n",
    "\n",
    "mongodb_db_host = cb104_addr.local_mongodb_host\n",
    "mongodb_db_name = \"keyword_filter\"\n",
    "mongodb_collection = paper_name + \"_news\"\n",
    "\n",
    "mariadb_host = cb104_addr.local_mariadb_host\n",
    "mariadb_user = cb104_addr.local_mariadb_user\n",
    "mariadb_pw = cb104_addr.local_mariadb_pw\n",
    "mariadb_db_name = \"news_db\"\n",
    "mariadb_tablename = paper_name + \"_news\"\n",
    "\n",
    "conn_md = MongoClient(mongodb_db_host)\n",
    "mdb = conn_md[mongodb_db_name]\n",
    "mcollection = mdb[mongodb_collection]\n",
    "\n",
    "conn = MySQLdb.connect(host=mariadb_host, user=mariadb_user, passwd=mariadb_pw, db=mariadb_db_name, charset=\"utf8\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "sql_command = \"select create_time,tag,title_keyword_1,title_keyword_2,title_keyword_3,keyword_1,keyword_2,keyword_3,\" \\\n",
    "              \"keyword_4,keyword_5,views_48 from \" + mariadb_tablename + \\\n",
    "              \" where views_48 is not null and create_time > '2019-02-07'\"\n",
    "cursor.execute(sql_command)\n",
    "sql_data = cursor.fetchall()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(len(sql_data))\n",
    "\n",
    "\n",
    "def take_second(elem):\n",
    "    return elem[1]\n",
    "\n",
    "\n",
    "# 讀取keyword資料\n",
    "keywordDict = {}\n",
    "count1 = 0\n",
    "with open(\"new_keyword0317.txt\",\"r\",encoding=\"utf-8\") as kwh:\n",
    "    data = kwh.read()\n",
    "    data_line = data.split(\"\\n\")\n",
    "    kwSet = set()\n",
    "    for i in range(1, len(data_line)-1):\n",
    "        # print(\"data\",data_line[i])\n",
    "        a = eval(data_line[i])\n",
    "\n",
    "        if a[0].strip().upper() not in keywordDict:\n",
    "            keywordDict[a[0].strip().upper()] = a[1]\n",
    "        else:\n",
    "            keywordDict[a[0].strip().upper()] = keywordDict[a[0].strip().upper()] + a[1]\n",
    "delList = []\n",
    "for keyword in keywordDict:\n",
    "    if keywordDict[keyword] < 100:\n",
    "        delList.append(keyword)\n",
    "\n",
    "for keyword in delList:\n",
    "    del keywordDict[keyword]\n",
    "\n",
    "for i in range(10,21):\n",
    "    if str(i) in keywordDict:\n",
    "        del keywordDict[str(i)]\n",
    "title = [\"k1_24\", \"k1_72\", \"k1_168\", \"k1_trend\",\n",
    "         \"k2_24\", \"k2_72\", \"k2_168\", \"k2_trend\",\n",
    "         \"k3_24\", \"k3_72\", \"k3_168\", \"k3_trend\", \"48hr_views\",\"tag\"]\n",
    "df_news = pd.DataFrame(columns=title)\n",
    "\n",
    "count_data = 0\n",
    "for sqlDataOneRow in sql_data:\n",
    "    newsCreateTime = sqlDataOneRow[0]\n",
    "    # print(newsCreateTime)\n",
    "    titleCount = 0\n",
    "    dfData = {}\n",
    "    keywordData = set()\n",
    "    # 這邊要判斷有沒有進重要字\n",
    "    for keywordPos in range(2, 10):\n",
    "        if sqlDataOneRow[keywordPos] is not None:\n",
    "            keywordData.add(sqlDataOneRow[keywordPos].strip().upper())\n",
    "\n",
    "    sqlKeywordList = []\n",
    "    for keyword in keywordData:\n",
    "        if keyword in keywordDict:\n",
    "            sqlKeywordList.append([keyword, keywordDict[keyword]])\n",
    "\n",
    "    if len(sqlKeywordList) >= 3:\n",
    "        count1 = count1 + 1\n",
    "        sqlKeywordList.sort(key=take_second, reverse=True)\n",
    "        # print(sqlKeywordList)\n",
    "    else:\n",
    "        sqlKeywordList.append(None)\n",
    "        sqlKeywordList.append(None)\n",
    "        sqlKeywordList.append(None)\n",
    "    count_data = count_data + 1\n",
    "    if count_data % 500 == 0:\n",
    "        print(\"已處理資料:\",count_data)\n",
    "    keyName = [\"k1\", \"k2\", \"k3\"]\n",
    "    try:\n",
    "        for keywordPos in range(3):\n",
    "            if sqlKeywordList[keywordPos] is None:\n",
    "                dfData[keyName[keywordPos]+\"_24\"] = 0\n",
    "                dfData[keyName[keywordPos]+\"_72\"] = 0\n",
    "                dfData[keyName[keywordPos]+\"_168\"] = 0\n",
    "                dfData[keyName[keywordPos] + \"_trend\"] = 0\n",
    "                continue\n",
    "            # views = [[0],[0],[0],[0],[0],[0],[0]]\n",
    "            views = [0,0,0,0,0,0,0]\n",
    "            m_data = mcollection.find({\"keyword\": sqlKeywordList[keywordPos][0]})[0]\n",
    "            # print(m_data)\n",
    "            for viewsCreateTimeStr in m_data[\"views\"]:\n",
    "                viewsCreateTime = datetime.strptime(viewsCreateTimeStr, \"%Y-%m-%d %H:%M\")\n",
    "                dayDiff = (newsCreateTime - viewsCreateTime).total_seconds() // 86400\n",
    "                dayDiff = int(dayDiff)\n",
    "                if 0 <= dayDiff < 7:\n",
    "                    # print(viewsCreateTime, newsCreateTime, dayDiff, m_data[\"views\"][viewsCreateTimeStr])\n",
    "                    views[dayDiff] = views[dayDiff] + int(m_data[\"views\"][viewsCreateTimeStr])\n",
    "                dfData[keyName[keywordPos]+\"_24\"] = views[0]\n",
    "                dfData[keyName[keywordPos]+\"_72\"] = views[1] + views[2]\n",
    "                dfData[keyName[keywordPos]+\"_168\"] = views[3] + views[4] + views[5] + views[6]\n",
    "                # 計算斜率\n",
    "                # model = LinearRegression(fit_intercept=True)\n",
    "                lm = LinearRegression()\n",
    "                # print(views)\n",
    "                lm.fit(np.array([[0], [-1], [-2], [-3], [-4], [-5], [-6]]), np.array(views))\n",
    "                # print(lm.intercept_)\n",
    "                # print(lm.coef_)\n",
    "                dfData[keyName[keywordPos] + \"_trend\"] = lm.coef_\n",
    "        dfData[\"48hr_views\"] = sqlDataOneRow[-1]\n",
    "        dfData[\"tag\"] = sqlDataOneRow[1]\n",
    "        df_news = df_news.append(dfData, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(sqlKeywordList)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news.to_pickle(\"df_news_3keyword_puls0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1555814\n",
      "{'一千以下', '百萬以下', '十萬以下', '超過百萬', '一萬以下'}\n"
     ]
    }
   ],
   "source": [
    "def change48VToClass(num):\n",
    "    if num <= 1000:\n",
    "        return \"一千以下\"\n",
    "    elif num <= 10000:\n",
    "        return \"一萬以下\"\n",
    "    elif num <= 100000:\n",
    "        return \"十萬以下\"\n",
    "    elif num <= 1000000:\n",
    "        return \"百萬以下\"\n",
    "    else:\n",
    "        return \"超過百萬\"\n",
    "\n",
    "print(max(list(df_news[\"48hr_views\"])))\n",
    "    \n",
    "df_news_cls = df_news\n",
    "df_news_cls[\"class\"] = df_news[\"48hr_views\"].apply(change48VToClass)\n",
    "\n",
    "a = set()\n",
    "for tmp in list(df_news_cls[\"class\"]):\n",
    "    a.add(tmp)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_total = df_news_cls.drop([\"class\",\"tag\",\"48hr_views\",\"k1_72\",\"k2_72\",\"k3_72\"],axis = 1)\n",
    "y_total = df_news_cls[\"class\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_total,y_total,test_size = 0.2)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=26, max_depth= 6)\n",
    "\n",
    "# np.average(cross_val_score(clf, x_train, y_train, cv=10))\n",
    "clf = clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正確率: 0.6323851203501094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = clf.predict(x_test)\n",
    "print(\"正確率:\",accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_total = df_news.drop([\"class\",\"tag\",\"48hr_views\",\"k1_72\",\"k2_72\",\"k3_72\"],axis = 1)\n",
    "y_total = df_news[\"48hr_views\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_total,y_total,test_size = 0.2)\n",
    "\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=26, max_depth= 6)\n",
    "\n",
    "# np.average(cross_val_score(clf, x_train, y_train, cv=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2score: 0.14170315088772822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "clf = clf.fit(x_train,y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"r2score:\",r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k1_24       0\n",
       "k1_168      0\n",
       "k1_trend    0\n",
       "k2_24       0\n",
       "k2_168      0\n",
       "k2_trend    0\n",
       "k3_24       0\n",
       "k3_168      0\n",
       "k3_trend    0\n",
       "k1_48       0\n",
       "k2_48       0\n",
       "k3_48       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
